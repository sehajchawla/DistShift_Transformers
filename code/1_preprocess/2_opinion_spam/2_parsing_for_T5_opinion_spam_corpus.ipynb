{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"notebook8a_T5_data_parsing.ipynb","private_outputs":true,"provenance":[{"file_id":"1VFsrur3Stewhq9voy9zrIQqx74SpZaaU","timestamp":1620213729124},{"file_id":"1t2v7f5nn3ejjLu-SXqkb1LGuDA0NIHm7","timestamp":1620206734558}],"collapsed_sections":[]},"environment":{"name":"common-cpu.m65","type":"gcloud","uri":"gcr.io/deeplearning-platform-release/base-cpu:m65"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"rkTLZ3I4_7c_"},"source":["#Fine-tuning T5 from the Huggingface Library Simple Transformers"]},{"cell_type":"markdown","metadata":{"id":"CSVlYZjTsmhC"},"source":["The primary internet resources for \n","\n","\n","*   Fine Tuning: https://simpletransformers.ai/docs/usage/\n","*   Batch Size: https://machinelearningmastery.com/how-to-control-the-speed-and-stability-of-training-neural-networks-with-gradient-descent-batch-size/\n","\n","\n","*   General: https://ai.googleblog.com/2020/02/exploring-transfer-learning-with-t5.html\n","*   Use: https://paperswithcode.com/method/t5\n","\n","\n","*   PyPi Example: https://pypi.org/project/simpletransformers/0.51.0/\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"WXiUiZSSyuo2"},"source":["%%capture\n","import pandas as pd\n","from pprint import pprint\n","import logging\n","# Making sure the environment is set up correctly for anyone running this notebook\n","import datetime\n","import json\n","import os\n","import pprint\n","import random\n","import string\n","import sys\n","import tensorflow as tf\n","import datetime as datetime\n","import numpy as np\n","from sklearn.model_selection import StratifiedShuffleSplit\n","import sklearn\n","from google.colab import drive\n","from tensorflow import keras\n","import re"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ToSWFSITLa1G"},"source":["# Settings\n","pd.set_option('display.max_rows', 500)\n","pd.set_option('display.max_columns', 500)\n","pd.set_option('display.width', 1000)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EyUjFnlbYbP7"},"source":["**Getting the Data**"]},{"cell_type":"code","metadata":{"id":"blEWqoL6aHHP"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"u-8-gBw1zmEG"},"source":["def download_and_load_dataset(force_download=True):\n","  return pd.read_csv(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_processedUTF8.csv\", encoding = 'UTF-8')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nkaA9fOEYbP9"},"source":["**Processing the data**\n","\n","Purpose:\n","1. T5 trainer and evaluator take in panda dataframes with three columns: \n","\n","*   prefix: A string indicating the task to perform,\n","*   input_text: The input text sequence,\n","*   target_text: The target sequence.\n","\n","We process our data to be in this form. The prefix value specifies the task we want the T5 model to perform. In our case, we use the prefix binary classification, since our objective is to classify a review as either real (0) or fake (1).\n","\n","Output:\n","1.   Yelp reviews dataset for training, and generating metrics for the trained model\n","2.    Hotels OPSPAM reviews dataset for evaluating the generalizability of the trained model\n","\n"]},{"cell_type":"code","metadata":{"id":"nsrfZpBh5Dv0"},"source":["#############################################################################\n","################################ Yelp dataset################################\n","#############################################################################\n","reviews = download_and_load_dataset()\n","reviews = reviews[['reviewText', 'fakeLabel', 'date']]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_57IQljLqems"},"source":["\n","def refinereviewText(row):\n","    return row['reviewText'].lower()\n","\n","def refinefakeLabel(row):\n","    if row['fakeLabel'] == -1:\n","        return 0\n","    else:\n","        return 1\n","\n","def getyear(row):\n","    date = str(row['date'])\n","    return int(date[-2:])\n","\n","reviews = reviews.dropna()\n","reviews['reviewText'] = reviews.apply(refinereviewText, axis=1)\n","reviews['fakeLabel'] = reviews.apply(refinefakeLabel, axis=1)\n","reviews['year'] = reviews.apply(getyear, axis=1)\n","\n","\n","df_zeros = reviews[reviews['fakeLabel'] == 0].sample(80466) #make divisible by 32? not necessary. model takes into account imperfect divisibility\n","df_ones = reviews[reviews['fakeLabel'] == 1].sample(80466) #.sample(80466)\n","df_combined = df_zeros.append(df_ones)\n","df_combined = df_combined.sample(frac=1).reset_index(drop=True)\n","df_smaller = df_combined.sample(frac=0.1).reset_index(drop=True)\n","df_smaller\n","\n","reviews = df_smaller.copy()\n","reviews = reviews.rename(columns={\"reviewText\": \"review\", \"fakeLabel\": \"deceptive\"})\n","reviews.deceptive = reviews.deceptive.astype(str)\n","\n","reviews.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/reviews_pickle.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EWiW8xDbTTt0"},"source":["**Base case for comparing with hotels**"]},{"cell_type":"code","metadata":{"id":"Qn9c2bRG5mc8"},"source":["yelp = reviews.copy()\n","yelp = yelp.rename(columns={\"review\": \"input_text\", \"deceptive\": \"target_text\" })\n","yelp = yelp[[\"input_text\", \"target_text\"]]\n","yelp[\"prefix\"] = \"binary classification\"\n","yelp.target_text = yelp.target_text.astype(str)\n","yelp.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nbO5cGVEUEeJ"},"source":["# Shuffle and split the data\n","cross_num = 4\n","splitter = StratifiedShuffleSplit(n_splits=5, random_state=910, test_size=0.2)\n","labels = [str(x) for x in reviews['deceptive']] #must change to string for T5, since it is a text-to-text model\n","train_indices, test_indices = [x for x in splitter.split(reviews['review'], labels)][cross_num]\n","\n","training_X = np.array([reviews['review'][x] for x in train_indices])\n","training_y = np.array([labels[x] for x in train_indices])\n","test_X = np.array([reviews['review'][x] for x in test_indices])\n","test_y = np.array([labels[x] for x in test_indices])\n","\n","# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n","label_list = ['0','1']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ps4ScIwEUTcf"},"source":["#Creating training and testing dataset. Format to input into the T5 model which requires a dataframe with three columns: input_text, target_text, and prefix.\n","yelp_train = pd.DataFrame(zip(training_X, training_y), columns=[\"input_text\", \"target_text\"])\n","yelp_test = pd.DataFrame(zip(test_X, test_y), columns=[\"input_text\", \"target_text\"])\n","\n","yelp_train[\"prefix\"] = \"binary classification\"\n","yelp_test[\"prefix\"] = \"binary classification\"\n","\n","yelp_test.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_test.pkl')\n","yelp_train.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_train.pkl')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QfsZxfvNUZou"},"source":["**Hotels dataset**"]},{"cell_type":"code","metadata":{"id":"kbuo-jHfUZN3"},"source":["#############################################################################\n","############################### Hotels dataset###############################\n","#############################################################################\n","import pandas as pd\n","def download_and_load_dataset(force_download=True):\n","  return pd.read_csv(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opinion_spam_corpusUTF8.csv\", encoding = 'UTF-8')\n","hotel_test = download_and_load_dataset()\n","hotel_test['reviewTest'] = hotel_test.apply(refinereviewText, axis=1)\n","hotel_test = hotel_test[['reviewText', 'fakeLabel']].astype(str)\n","hotel_test = hotel_test.rename(columns={\"reviewText\": \"input_text\", \"fakeLabel\": \"target_text\"})\n","hotel_test[\"prefix\"] = \"binary classification\"\n","\n","hotel_test.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/hotel_test.pkl')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9csWef6u6ar8"},"source":["# Hotel train test split, tho confusing will name as train_ii and test_ii\n","cross_num = 4\n","\n","splitter = StratifiedShuffleSplit(n_splits=5, random_state=910, test_size=0.2)\n","labels = [str(x) for x in hotel_test['target_text']] #must change to string for T5, since it is a text-to-text model\n","train_indices, test_indices = [x for x in splitter.split(hotel_test['input_text'], labels)][cross_num]\n","\n","training_X = np.array([hotel_test['input_text'][x] for x in train_indices])\n","training_y = np.array([labels[x] for x in train_indices])\n","test_X = np.array([hotel_test['input_text'][x] for x in test_indices])\n","test_y = np.array([labels[x] for x in test_indices])\n","\n","# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n","label_list = ['0','1']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rIl4Ek6F7Gz7"},"source":["#Creating training and testing dataset. Format to input into the T5 model which requires a dataframe with three columns: input_text, target_text, and prefix.\n","hotel_trainii = pd.DataFrame(zip(training_X, training_y), columns=[\"input_text\", \"target_text\"])\n","hotel_testii = pd.DataFrame(zip(test_X, test_y), columns=[\"input_text\", \"target_text\"])\n","\n","hotel_trainii[\"prefix\"] = \"binary classification\"\n","hotel_testii[\"prefix\"] = \"binary classification\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6nK33PER7dYe"},"source":["import pandas as pd\n","hotel_testii.target_text = hotel_testii.target_text.astype(str)\n","hotel_testii.target_text = hotel_testii.target_text.astype(str)\n","\n","hotel_testii.target_text = hotel_testii.target_text.astype(str)\n","hotel_testii.target_text = hotel_testii.target_text.astype(str)\n","\n","hotel_testii.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/hotel_testii.pkl')\n","hotel_trainii.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/hotel_trainii.pkl')\n","\n","hotel_trainii.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"t1-j8MEYTNz-"},"source":["**Time shift**"]},{"cell_type":"code","metadata":{"id":"VsEdgGv4RDHq"},"source":["# Create old versus new version\n","reviews_old = reviews[reviews['year'] < 14]\n","reviews_new = reviews[reviews['year'] >= 14]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TKINMwEj6GES"},"source":["reviews_old = reviews_old[['review', 'deceptive']]\n","reviews_new = reviews_new[['review', 'deceptive']]\n","reviews_old = reviews_old.sample(frac=1).reset_index(drop=True)\n","reviews_new = reviews_new.sample(frac=1).reset_index(drop=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eXAfO4eB-WWv"},"source":["\n","# Genuine/Fake split in old and new datasets\n","print(\"% genuine in old and new sample, respectively:\" , reviews_old.value_counts('deceptive')[0]/np.sum(reviews_old.value_counts('deceptive')), reviews_new.value_counts('deceptive')[0]/np.sum(reviews_new.value_counts('deceptive')))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zsa0Zo8tYbP-"},"source":["# Counts in old and new datasets\n","print(\"Number of old reviews:\", len(reviews_old))\n","print(\"Number of new reviews:\", len(reviews_new))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7GHYlsd2ROUU"},"source":["# Shuffle and split the data\n","cross_num = 4\n","splitter = StratifiedShuffleSplit(n_splits=5, random_state=910, test_size=0.2)\n","labels = [str(x) for x in reviews_old['deceptive']] #must change to string for T5, since it is a text-to-text model\n","train_indices, test_indices = [x for x in splitter.split(reviews_old['review'], labels)][cross_num]\n","\n","training_X = np.array([reviews_old['review'][x] for x in train_indices])\n","training_y = np.array([labels[x] for x in train_indices])\n","test_X = np.array([reviews_old['review'][x] for x in test_indices])\n","test_y = np.array([labels[x] for x in test_indices])\n","\n","new_X = reviews_new['review']\n","new_y = reviews_new['deceptive']\n","\n","# Label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n","label_list = ['0','1']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hcaqrWmblDGX"},"source":["# Creating training and testing dataset. Format to input into the T5 model which requires a dataframe with three columns: input_text, target_text, and prefix.\n","yelp_old_train = pd.DataFrame(zip(training_X, training_y), columns=[\"input_text\", \"target_text\"])\n","yelp_old_test = pd.DataFrame(zip(test_X, test_y), columns=[\"input_text\", \"target_text\"])\n","yelp_new = pd.DataFrame(zip(new_X, new_y), columns=[\"input_text\", \"target_text\"])\n","\n","yelp_old_train[\"prefix\"] = \"binary classification\"\n","yelp_old_test[\"prefix\"] = \"binary classification\"\n","yelp_new[\"prefix\"] = \"binary classification\"\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-hoZQaAxSmbk"},"source":["# Pickle\n","yelp_old_train.to_pickle(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_old_train.pkl\")\n","yelp_old_test.to_pickle(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_old_test.pkl\")\n","yelp_new.to_pickle(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_new.pkl\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tfd7ORppZ5ag"},"source":["**Top three restaurants**"]},{"cell_type":"code","metadata":{"id":"pdDRDdLNZ4hC"},"source":["reviews_top3 = pd.read_csv(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelptop3_balancedUTF8.csv\", encoding = 'UTF-8')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p6nWEUPMcCn1"},"source":["reviews_top3.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWiICrKHcnc0"},"source":["reviews_top3['prefix']= \"binary classificatio\"\n","reviews_top3 = reviews_top3.rename(columns = {\"reviewText\":\"input_text\", \"fakeLabel_str\": \"target_text\", \"restaurantID\": \"rid\"})"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dLxGaZqEc7oU"},"source":["reviews_top3.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"muNUyLcocSJT"},"source":["yelp_top = reviews_top3[reviews_top3['rid']==1][['input_text', \"target_text\", \"prefix\"]]\n","yelp_23 = reviews_top3[reviews_top3['rid']!=1][['input_text', \"target_text\", \"prefix\"]]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iv4qAy8EFtb-"},"source":["# Hotel train test split, tho confusing will name as train_ii and test_ii\n","cross_num = 4\n","\n","splitter = StratifiedShuffleSplit(n_splits=5, random_state=910, test_size=0.2)\n","labels = [str(x) for x in yelp_top['target_text']] #must change to string for T5, since it is a text-to-text model\n","train_indices, test_indices = [x for x in splitter.split(yelp_top['input_text'], labels)][cross_num]\n","\n","training_X = np.array([yelp_top['input_text'][x] for x in train_indices])\n","training_y = np.array([labels[x] for x in train_indices])\n","test_X = np.array([yelp_top['input_text'][x] for x in test_indices])\n","test_y = np.array([labels[x] for x in test_indices])\n","\n","# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n","label_list = ['0','1']\n","\n","#Creating training and testing dataset. Format to input into the T5 model which requires a dataframe with three columns: input_text, target_text, and prefix.\n","yelp_top_train = pd.DataFrame(zip(training_X, training_y), columns=[\"input_text\", \"target_text\"])\n","yelp_top_test = pd.DataFrame(zip(test_X, test_y), columns=[\"input_text\", \"target_text\"])\n","\n","yelp_top_train[\"prefix\"] = \"binary classification\"\n","yelp_top_test[\"prefix\"] = \"binary classification\"\n","\n","\n","yelp_top_train.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_top_train.pkl')\n","yelp_top_test.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_top_test.pkl')\n","yelp_23.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_23.pkl')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DVUE4k7wczWW"},"source":["# Pickle\n","\n","yelp_top_train.to_pickle(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_top_train.pkl\")\n","yelp_top_test.to_pickle(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_top_test.pkl\")\n","\n","\n","yelp_23.to_pickle(\"/content/drive/My Drive/6862_FakeReviewDetection/data/raw/yelp_23.pkl\")\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZlwDGFTs1Aeq"},"source":["**Opspam**"]},{"cell_type":"code","metadata":{"id":"0JkxRlRD1bJb"},"source":["# Shuffle and split the data\n","cross_num = 4\n","splitter = StratifiedShuffleSplit(n_splits=5, random_state=910, test_size=0.2)\n","\n","def shuffle_split(df):\n","  train_indices, test_indices = [x for x in splitter.split(df['input_text'], df['target_text'])][cross_num]\n","  \n","  training_X = np.array([df['input_text'][x] for x in train_indices])\n","  training_y = np.array([df['target_text'][x] for x in train_indices])\n","\n","  test_X = np.array([df['input_text'][x] for x in test_indices])\n","  test_y = np.array([df['target_text'][x] for x in test_indices])\n","\n","  train = pd.DataFrame(zip(training_X, training_y), columns=[\"input_text\", \"target_text\"])\n","  test = pd.DataFrame(zip(test_X, test_y), columns=[\"input_text\", \"target_text\"])\n","\n","  train['prefix'] = \"binary classification\"\n","  test['prefix'] = \"binary classification\"\n","  return (train, test)\n","\n","# label_list is the list of labels, i.e. True, False or 0, 1 or 'dog', 'cat'\n","label_list = ['0','1']"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dnoE2S3S1BoI"},"source":["opspam = pd.read_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/OpSpamSentimentReviews.pkl')\n","opspam.head()\n","\n","\n","opspam = opspam.rename(columns = {\"fakeLabel\": \"target_text\", \"reviewText\": \"input_text\"})\n","opspam.target_text = opspam.target_text.astype(str)\n","opspam[\"prefix\"] = \"binary classification\"\n","\n","opspam_pos = opspam[opspam['polarity']==\"positive\"][[\"target_text\", \"input_text\", \"prefix\"]].reset_index(drop=True)\n","opspam_neg = opspam[opspam['polarity']!=\"positive\"][[\"target_text\", \"input_text\", \"prefix\"]].reset_index(drop=True)\n","\n","print(opspam_neg)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"13xiPcMt5vgn"},"source":["#Create train and testing datasets using user defined fn (shuffle_split) and then concatenating a \"prefix\" column\n","opspam_pos_train, opspam_pos_test = shuffle_split(opspam_pos)\n","opspam_neg_train, opspam_neg_test = shuffle_split(opspam_neg)\n","print(opspam_pos_train, opspam_neg_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvVXLVTC6dJB"},"source":["\n","opspam_neg.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opspam_neg.pkl')\n","opspam_pos.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opspam_pos.pkl')\n","\n","opspam_pos_train.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opspam_pos_train.pkl')\n","opspam_pos_test.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opspam_pos_test.pkl')\n","\n","opspam_neg_train.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opspam_neg_train.pkl')\n","opspam_neg_test.to_pickle('/content/drive/My Drive/6862_FakeReviewDetection/data/raw/opspam_neg_test.pkl')"],"execution_count":null,"outputs":[]}]}